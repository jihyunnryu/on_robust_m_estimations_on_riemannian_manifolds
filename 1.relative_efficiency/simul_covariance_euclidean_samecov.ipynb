{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "945d74e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(*str(os.getcwd()).split('\\\\')[:-1]).replace(':',':\\\\'))\n",
    "import riemannian_robust_m_estimator as rrm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os, time, pickle\n",
    "import math\n",
    "from scipy.stats import chi2\n",
    "\n",
    "import geomstats.backend as gs\n",
    "import geomstats.visualization as visualization\n",
    "from geomstats.geometry.euclidean import Euclidean\n",
    "from geomstats.geometry.hyperboloid import Hyperboloid\n",
    "from geomstats.geometry.hypersphere import Hypersphere\n",
    "from geomstats.geometry.poincare_ball import PoincareBall\n",
    "from geomstats.geometry.poincare_half_space import PoincareHalfSpace\n",
    "from geomstats.geometry.spd_matrices import SPDMatrices\n",
    "from geomstats.geometry.special_euclidean import SpecialEuclidean\n",
    "from geomstats.geometry.special_orthogonal import SpecialOrthogonal\n",
    "from geomstats.learning.frechet_mean import FrechetMean\n",
    "from geomstats.learning.geometric_median import GeometricMedian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "489df9c4-b4fa-495b-bde4-51246f1f3827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.getLogger('root').setLevel(logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff609cc8",
   "metadata": {},
   "source": [
    "# Sample mean simulation code\n",
    "1) Set $\\mu=(0,0,...,0)$ and covariance matrix $\\Sigma$ which is the same as hyperbolic(hyperboloid)/euclidean\n",
    "2) Generate random samples $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ from pre-specified distribution with $\\mu$, covariance matrix $\\Sigma$\n",
    "3) Get $\\mathbf{X}^* = Exp_{\\mu}(\\mathbf{X}) = \\mathbf{X}$ for manifold-valued sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d38d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def riemannian_sample_variance_comparison_euclidean(manifold, mu, cov, n_samples, pop_dist_type = 'gaussian', sample_iter=100, seed=None):\n",
    "\n",
    "    max_iter_graddescent = 2048\n",
    "    epsilon = 1e-7\n",
    "    cutoff_ptiles = [5,10,15,20,25,30,35,40,45,50,60,70,75,80,82.13,85,90,95,99,99.73]\n",
    "    results = {\n",
    "        'mean':{'fm':[],'gm':[],\n",
    "               },\n",
    "        'var':{'fm':[],'gm':[],\n",
    "               },\n",
    "        'sq_bias':{'fm':[],'gm':[],\n",
    "               },\n",
    "        'sample_mean_var':{},\n",
    "        'sample_var_mean':{},\n",
    "        'sample_var_var':{},\n",
    "        'sq_bias_mean':{},\n",
    "        'sq_bias_var':{},\n",
    "        'invalid':[],\n",
    "        'cov':cov,\n",
    "        'distances':[],\n",
    "        'cutoff':{}\n",
    "    }\n",
    "    if seed is not None:\n",
    "        gs.random.seed(seed)\n",
    "        my_rng = np.random.default_rng(seed=seed)\n",
    "    else:\n",
    "        my_rng = np.random.default_rng()\n",
    "\n",
    "    for cutoff_pct in cutoff_ptiles:\n",
    "        results['cutoff'][cutoff_pct] = []\n",
    "    m_est_type_lb = {'mono':('huber',1.345),'softr':('cauchy',2.3849),'hardr':('biweight',4.6851)}\n",
    "    for i in range(sample_iter):\n",
    "        if pop_dist_type == 'gaussian':\n",
    "            tangent_data = np.random.multivariate_normal(mean=mu, cov=cov, size=n_samples)\n",
    "        elif pop_dist_type == 't':\n",
    "            tangent_data = sample_mv_t(mean=mu, Sigma=cov, n=n_samples, nu=4, rng=my_rng)\n",
    "        elif pop_dist_type == 'laplace':\n",
    "            tangent_data = sample_mv_laplace(mean=mu, Sigma=cov, n=n_samples, rng=my_rng)\n",
    "        elif pop_dist_type == 'NIG':\n",
    "            tangent_data = sample_mv_nig(mean=mu, Sigma=cov, n=n_samples, alpha=1.5, delta=1.0, rng=my_rng)\n",
    "\n",
    "        # tangent_data = np.hstack((tangent_data, np.expand_dims(np.repeat(0,n_samples), -1)))\n",
    "        logs = tangent_data\n",
    "        data = manifold.metric.exp(logs, mu)\n",
    "\n",
    "        assert (data==logs).all()\n",
    "       \n",
    "        dists = manifold.metric.dist(data, mu)\n",
    "        results['distances'].append(dists)\n",
    "        if i==0:\n",
    "            print(f'distances distribution(avg:{np.mean(dists):.2f}/max:{np.max(dists):.2f}/min:{np.min(dists):.2f})')\n",
    "\n",
    "        fm = rrm.RiemannianRobustMestimator(\n",
    "                    space=manifold,\n",
    "                    method='default',\n",
    "                    m_estimator='custom',\n",
    "                    critical_value=None,\n",
    "                    init_point_method='mean-projection',\n",
    "                )\n",
    "        fm.set_loss(squaredist)\n",
    "        fm.set(init_step_size=0.5, max_iter=max_iter_graddescent, epsilon=epsilon)\n",
    "        fm.fit(data)\n",
    "                \n",
    "        if len(fm.estimate_.losses)>max_iter_graddescent-50:\n",
    "            results['invalid'].append(f'{res_lb}_{i}')\n",
    "            results['mean'][res_lb].append(gs.array([9999]*len(data[0])))\n",
    "            results['var'][res_lb].append(9999)\n",
    "            results['sq_bias'][res_lb].append(9999)\n",
    "        else:\n",
    "            results['mean']['fm'].append(fm.estimate_.x)\n",
    "            results['var']['fm'].append(\n",
    "                rrm.riemannian_variance(manifold, data, base=fm.estimate_.x)\n",
    "            )\n",
    "            bias = fm.estimate_.x - mu\n",
    "            results['sq_bias']['fm'].append(\n",
    "                bias.T @ bias\n",
    "            )\n",
    "        \n",
    "   \n",
    "        gm = GeometricMedian(manifold, lr=0.5, max_iter=max_iter_graddescent, epsilon=epsilon)\n",
    "        gm.fit(data)\n",
    "        results['mean']['gm'].append(gm.estimate_)\n",
    "        results['var']['gm'].append(\n",
    "            rrm.riemannian_variance(manifold, data, base=gm.estimate_)\n",
    "        )\n",
    "        bias = gm.estimate_ - mu\n",
    "        results['sq_bias']['gm'].append(\n",
    "            bias.T @ bias\n",
    "        )\n",
    "       \n",
    "        for cutoff_pct in cutoff_ptiles:\n",
    "            ptile_ix = int(len(dists)*cutoff_pct/100)-1\n",
    "            c = np.sort(dists)[ptile_ix]\n",
    "            results['cutoff'][cutoff_pct].append(c)\n",
    "            for m_est_tp,(m_est_lb,c_95) in m_est_type_lb.items():\n",
    "                res_lb = f'{m_est_tp}_{cutoff_pct:.2f}'\n",
    "                if res_lb not in results['mean'].keys():\n",
    "                    results['mean'][res_lb] = []\n",
    "                    results['var'][res_lb] = []\n",
    "                    results['sq_bias'][res_lb] = []\n",
    "                    \n",
    "                # print(f'{res_lb}({c:.2f}) start')\n",
    "                m_est = rrm.RiemannianRobustMestimator(\n",
    "                    space=manifold, method='default', m_estimator=m_est_lb, critical_value=c,init_point_method='mean-projection',\n",
    "                )\n",
    "                m_est.set(init_step_size=5 if m_est_lb == 'biweight' else 0.5, max_iter=max_iter_graddescent, epsilon=epsilon)\n",
    "                m_est.fit(data)\n",
    "                if len(m_est.estimate_.losses)>max_iter_graddescent-50:\n",
    "                    results['invalid'].append(f'{res_lb}_{i}')\n",
    "                    results['mean'][res_lb].append(gs.array([9999]*len(data[0])))\n",
    "                    results['var'][res_lb].append(9999)\n",
    "                    results['sq_bias'][res_lb].append(9999)\n",
    "                else:\n",
    "                    results['mean'][res_lb].append(m_est.estimate_.x)\n",
    "                    results['var'][res_lb].append(\n",
    "                        rrm.riemannian_variance(manifold, data, base=m_est.estimate_.x)\n",
    "                    )\n",
    "                    bias = m_est.estimate_.x - mu\n",
    "                    results['sq_bias'][res_lb].append(\n",
    "                        bias.T @ bias\n",
    "                    )\n",
    "               \n",
    "\n",
    "    for lb in results['mean'].keys():\n",
    "        results['sample_mean_var'][lb] = rrm.riemannian_variance(manifold, gs.array([i for i in results['mean'][lb] if i[0]!=9999])),\n",
    "        results['sample_var_mean'][lb] = np.mean([i for i in results['var'][lb] if i!=9999]),\n",
    "        results['sample_var_var'][lb] = np.var([i for i in results['var'][lb] if i!=9999]),\n",
    "        results['sq_bias_mean'][lb] = np.mean([i for i in results['sq_bias'][lb] if i!=9999]),\n",
    "        results['sq_bias_var'][lb] = np.var([i for i in results['sq_bias'][lb] if i!=9999]),\n",
    "       \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# --------- 유틸 ---------\n",
    "def chol_psd_for_cov(Sigma, scale=1.0, eps=1e-12):\n",
    "    \"\"\"L L^T = Sigma / scale 가 되도록 수치안정 고유분해 기반 'Cholesky-like'.\"\"\"\n",
    "    Sigma = np.asarray(Sigma, float)\n",
    "    vals, vecs = np.linalg.eigh(Sigma)\n",
    "    vals = np.clip(vals, eps, None)\n",
    "    target = vals / float(scale)\n",
    "    return vecs @ np.diag(np.sqrt(target)) @ vecs.T\n",
    "\n",
    "# Inverse-Gaussian(μ, λ) 샘플러 (Michael–Schucany–Haas)\n",
    "def sample_inverse_gaussian(mu, lam, size, rng):\n",
    "    v = rng.standard_normal(size=size)\n",
    "    y = v**2\n",
    "    x = mu + (mu**2 * y)/(2*lam) - (mu/(2*lam))*np.sqrt(4*mu*lam*y + mu**2 * y**2)\n",
    "    u = rng.uniform(size=size)\n",
    "    w = np.where(u <= mu/(mu + x), x, (mu**2)/x)\n",
    "    return w\n",
    "\n",
    "# --------- 1) Student-t_ν (ν>2) ---------\n",
    "def sample_mv_t(mean, Sigma, n, nu, rng=None):\n",
    "    \"\"\"\n",
    "    mean: (d,), Sigma: (d,d), nu>2\n",
    "    공분산이 정확히 Sigma가 되도록 자동 스케일.\n",
    "    \"\"\"\n",
    "    assert nu > 2, \"Student-t에서 공분산 유한/매칭은 ν>2 필요.\"\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    E_W = nu / (nu - 2.0)\n",
    "    L = chol_psd_for_cov(Sigma, scale=E_W)\n",
    "    G = rng.chisquare(df=nu, size=n)          # χ²_ν\n",
    "    W = nu / G                                # mixture\n",
    "    Z = rng.standard_normal((n, mean.size))   # N(0, I)\n",
    "    X = mean + (np.sqrt(W)[:, None] * (Z @ L.T))\n",
    "    return X\n",
    "\n",
    "# --------- 2) Elliptical Laplace ---------\n",
    "def sample_mv_laplace(mean, Sigma, n, rng=None):\n",
    "    \"\"\"\n",
    "    타원형 Laplace: X|W ~ N(mean, W Sigma), W ~ Exp(1), E[W]=1\n",
    "    -> L L^T = Sigma\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    L = chol_psd_for_cov(Sigma, scale=1.0)\n",
    "    W = rng.exponential(scale=1.0, size=n)\n",
    "    Z = rng.standard_normal((n, mean.size))\n",
    "    X = mean + (np.sqrt(W)[:, None] * (Z @ L.T))\n",
    "    return X\n",
    "\n",
    "# --------- 3) NIG (대칭형, β=0) ---------\n",
    "def sample_mv_nig(mean, Sigma, n, alpha=1.5, delta=1.0, rng=None):\n",
    "    \"\"\"\n",
    "    대칭 NIG: W ~ IG(μ=δ/α, λ=δα), E[W]=δ/α\n",
    "    -> L L^T = Sigma / (δ/α)\n",
    "    (왜도 β!=0 도 가능하지만, 그 경우 Cov에 Var(W)ββ^T가 추가되므로 별도 스케일 조정 필요)\n",
    "    \"\"\"\n",
    "    assert alpha > 0 and delta > 0\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    muW = delta / alpha\n",
    "    lamW = delta * alpha\n",
    "    L = chol_psd_for_cov(Sigma, scale=muW)\n",
    "    W = sample_inverse_gaussian(mu=muW, lam=lamW, size=n, rng=rng)\n",
    "    Z = rng.standard_normal((n, mean.size))\n",
    "    X = mean + (np.sqrt(W)[:, None] * (Z @ L.T))\n",
    "    return X\n",
    "\n",
    "def squaredist(space,points,base,critical_value,weights=None,loss_and_grad=True):\n",
    "    n = len(points)\n",
    "    logs = space.metric.log(points,base)\n",
    "    dists = space.metric.dist(points,base)\n",
    "\n",
    "    loss = gs.sum(dists**2)/n\n",
    "    if not loss_and_grad:\n",
    "        return loss\n",
    "    grad = -2*gs.sum(logs,axis=0)/n\n",
    "    return loss, space.to_tangent(grad,base)\n",
    "\n",
    "    \n",
    "# # --------- 사용 예시 ---------\n",
    "# if __name__ == \"__main__\":\n",
    "#     d, n = 3, 10000\n",
    "#     mu = np.zeros(d)\n",
    "#     Sigma = np.array([[1.0, 0.6, 0.0],\n",
    "#                       [0.6, 1.0, 0.2],\n",
    "#                       [0.0, 0.2, 1.5]])\n",
    "\n",
    "#     X_t   = sample_mv_t(mu, Sigma, n, nu=4.0)\n",
    "#     X_lap = sample_mv_laplace(mu, Sigma, n)\n",
    "#     X_nig = sample_mv_nig(mu, Sigma, n, alpha=1.8, delta=1.0)\n",
    "\n",
    "#     # 샘플 공분산 확인(유한표본 오차 있음)\n",
    "#     print(np.cov(X_t,   rowvar=False)[:2,:2])\n",
    "#     print(np.cov(X_lap, rowvar=False)[:2,:2])\n",
    "#     print(np.cov(X_nig, rowvar=False)[:2,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f06106-02a3-4bdb-8371-1b04f1e972e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('covs.pkl','rb') as f_:\n",
    "    covs = pickle.load(f_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e9b542-d129-4855-a301-1a99b1415083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distances distribution(avg:0.31/max:0.51/min:0.17)\n",
      "[0] dimension 20, full-rank, gaussian done: 193.8627908229828 seconds elapsed...\n",
      "distances distribution(avg:0.31/max:0.52/min:0.13)\n",
      "[0] dimension 20, half-rank, gaussian done: 383.9768600463867 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:0.99/min:0.02)\n",
      "[0] dimension 20, low-rank, gaussian done: 523.328501701355 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:1.22/min:0.08)\n",
      "[0] dimension 20, full-rank, t done: 605.5773940086365 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:2.42/min:0.07)\n",
      "[0] dimension 20, half-rank, t done: 722.8625636100769 seconds elapsed...\n",
      "distances distribution(avg:0.24/max:1.89/min:0.01)\n",
      "[0] dimension 20, low-rank, t done: 879.5996775627136 seconds elapsed...\n",
      "distances distribution(avg:0.29/max:0.96/min:0.00)\n",
      "[0] dimension 20, full-rank, laplace done: 953.0453615188599 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:0.90/min:0.01)\n",
      "[0] dimension 20, half-rank, laplace done: 1057.4104158878326 seconds elapsed...\n",
      "distances distribution(avg:0.25/max:1.54/min:0.00)\n",
      "[0] dimension 20, low-rank, laplace done: 1218.9431862831116 seconds elapsed...\n",
      "distances distribution(avg:0.31/max:0.42/min:0.22)\n",
      "[0] dimension 50, full-rank, gaussian done: 1323.4774615764618 seconds elapsed...\n",
      "distances distribution(avg:0.32/max:0.47/min:0.18)\n",
      "[0] dimension 50, half-rank, gaussian done: 1508.195234298706 seconds elapsed...\n",
      "distances distribution(avg:0.30/max:0.66/min:0.06)\n",
      "[0] dimension 50, low-rank, gaussian done: 1698.6172015666962 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:1.26/min:0.09)\n",
      "[0] dimension 50, full-rank, t done: 1776.2504713535309 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:1.75/min:0.08)\n",
      "[0] dimension 50, half-rank, t done: 1863.6138327121735 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:2.36/min:0.04)\n",
      "[0] dimension 50, low-rank, t done: 2045.275369644165 seconds elapsed...\n",
      "distances distribution(avg:0.29/max:0.95/min:0.02)\n",
      "[0] dimension 50, full-rank, laplace done: 2130.819078683853 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:1.00/min:0.01)\n",
      "[0] dimension 50, half-rank, laplace done: 2221.675940990448 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:1.25/min:0.01)\n",
      "[0] dimension 50, low-rank, laplace done: 2389.3336477279663 seconds elapsed...\n",
      "distances distribution(avg:0.31/max:0.50/min:0.18)\n",
      "[1] dimension 20, full-rank, gaussian done: 2587.51704621315 seconds elapsed...\n",
      "distances distribution(avg:0.31/max:0.59/min:0.13)\n",
      "[1] dimension 20, half-rank, gaussian done: 2781.270887851715 seconds elapsed...\n",
      "distances distribution(avg:0.29/max:0.84/min:0.02)\n",
      "[1] dimension 20, low-rank, gaussian done: 2920.217046737671 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:1.48/min:0.08)\n",
      "[1] dimension 20, full-rank, t done: 3003.358312368393 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:1.49/min:0.06)\n",
      "[1] dimension 20, half-rank, t done: 3122.8806738853455 seconds elapsed...\n",
      "distances distribution(avg:0.25/max:2.30/min:0.01)\n",
      "[1] dimension 20, low-rank, t done: 3267.6685721874237 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:0.96/min:0.01)\n",
      "[1] dimension 20, full-rank, laplace done: 3336.720270872116 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:0.91/min:0.01)\n",
      "[1] dimension 20, half-rank, laplace done: 3435.779806613922 seconds elapsed...\n",
      "distances distribution(avg:0.25/max:1.20/min:0.01)\n",
      "[1] dimension 20, low-rank, laplace done: 3600.4341304302216 seconds elapsed...\n",
      "distances distribution(avg:0.31/max:0.43/min:0.21)\n",
      "[1] dimension 50, full-rank, gaussian done: 3713.3068816661835 seconds elapsed...\n",
      "distances distribution(avg:0.32/max:0.46/min:0.20)\n",
      "[1] dimension 50, half-rank, gaussian done: 3911.8518607616425 seconds elapsed...\n",
      "distances distribution(avg:0.30/max:0.65/min:0.06)\n",
      "[1] dimension 50, low-rank, gaussian done: 4111.7404227256775 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:1.22/min:0.09)\n",
      "[1] dimension 50, full-rank, t done: 4186.638423442841 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:1.60/min:0.08)\n",
      "[1] dimension 50, half-rank, t done: 4274.152093887329 seconds elapsed...\n",
      "distances distribution(avg:0.26/max:1.84/min:0.05)\n",
      "[1] dimension 50, low-rank, t done: 4452.800481081009 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:0.86/min:0.01)\n",
      "[1] dimension 50, full-rank, laplace done: 4537.961708068848 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:1.00/min:0.00)\n",
      "[1] dimension 50, half-rank, laplace done: 4626.105787992477 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:1.25/min:0.01)\n",
      "[1] dimension 50, low-rank, laplace done: 4783.232698202133 seconds elapsed...\n",
      "distances distribution(avg:0.31/max:0.49/min:0.19)\n",
      "[2] dimension 20, full-rank, gaussian done: 5003.2064473629 seconds elapsed...\n",
      "distances distribution(avg:0.31/max:0.55/min:0.11)\n",
      "[2] dimension 20, half-rank, gaussian done: 5211.174043893814 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:0.98/min:0.01)\n",
      "[2] dimension 20, low-rank, gaussian done: 5356.325803518295 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:1.16/min:0.09)\n",
      "[2] dimension 20, full-rank, t done: 5441.676556110382 seconds elapsed...\n",
      "distances distribution(avg:0.26/max:1.30/min:0.07)\n",
      "[2] dimension 20, half-rank, t done: 5569.54650592804 seconds elapsed...\n",
      "distances distribution(avg:0.24/max:1.54/min:0.01)\n",
      "[2] dimension 20, low-rank, t done: 5721.021317481995 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:1.10/min:0.01)\n",
      "[2] dimension 20, full-rank, laplace done: 5794.481117010117 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:1.03/min:0.01)\n",
      "[2] dimension 20, half-rank, laplace done: 5895.454512834549 seconds elapsed...\n",
      "distances distribution(avg:0.25/max:1.31/min:0.00)\n",
      "[2] dimension 20, low-rank, laplace done: 6076.69357252121 seconds elapsed...\n",
      "distances distribution(avg:0.31/max:0.43/min:0.23)\n",
      "[2] dimension 50, full-rank, gaussian done: 6193.822364807129 seconds elapsed...\n",
      "distances distribution(avg:0.31/max:0.46/min:0.20)\n",
      "[2] dimension 50, half-rank, gaussian done: 6390.750208616257 seconds elapsed...\n",
      "distances distribution(avg:0.30/max:0.64/min:0.05)\n",
      "[2] dimension 50, low-rank, gaussian done: 6586.232004880905 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:2.39/min:0.09)\n",
      "[2] dimension 50, full-rank, t done: 6664.295592308044 seconds elapsed...\n",
      "distances distribution(avg:0.29/max:1.99/min:0.09)\n",
      "[2] dimension 50, half-rank, t done: 6749.930090665817 seconds elapsed...\n",
      "distances distribution(avg:0.26/max:1.41/min:0.04)\n",
      "[2] dimension 50, low-rank, t done: 6932.114899635315 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:1.03/min:0.01)\n",
      "[2] dimension 50, full-rank, laplace done: 7016.470556497574 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:0.91/min:0.01)\n",
      "[2] dimension 50, half-rank, laplace done: 7104.206842184067 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:1.14/min:0.00)\n",
      "[2] dimension 50, low-rank, laplace done: 7257.5234298706055 seconds elapsed...\n",
      "distances distribution(avg:0.31/max:0.45/min:0.18)\n",
      "[3] dimension 20, full-rank, gaussian done: 7466.736728429794 seconds elapsed...\n",
      "distances distribution(avg:0.31/max:0.56/min:0.13)\n",
      "[3] dimension 20, half-rank, gaussian done: 7663.182842493057 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:0.86/min:0.02)\n",
      "[3] dimension 20, low-rank, gaussian done: 7812.03386926651 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:1.99/min:0.08)\n",
      "[3] dimension 20, full-rank, t done: 7902.515005350113 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:1.89/min:0.06)\n",
      "[3] dimension 20, half-rank, t done: 8028.504615783691 seconds elapsed...\n",
      "distances distribution(avg:0.25/max:1.81/min:0.01)\n",
      "[3] dimension 20, low-rank, t done: 8183.119054555893 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:1.11/min:0.00)\n",
      "[3] dimension 20, full-rank, laplace done: 8259.785016298294 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:1.20/min:0.00)\n",
      "[3] dimension 20, half-rank, laplace done: 8360.459547042847 seconds elapsed...\n",
      "distances distribution(avg:0.25/max:1.35/min:0.01)\n",
      "[3] dimension 20, low-rank, laplace done: 8523.326768159866 seconds elapsed...\n",
      "distances distribution(avg:0.31/max:0.43/min:0.21)\n",
      "[3] dimension 50, full-rank, gaussian done: 8640.639693021774 seconds elapsed...\n",
      "distances distribution(avg:0.31/max:0.45/min:0.17)\n",
      "[3] dimension 50, half-rank, gaussian done: 8855.526249170303 seconds elapsed...\n",
      "distances distribution(avg:0.30/max:0.70/min:0.07)\n",
      "[3] dimension 50, low-rank, gaussian done: 9053.93426990509 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:3.85/min:0.08)\n",
      "[3] dimension 50, full-rank, t done: 9128.371423006058 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:1.17/min:0.09)\n",
      "[3] dimension 50, half-rank, t done: 9214.742405176163 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:2.06/min:0.04)\n",
      "[3] dimension 50, low-rank, t done: 9395.063185214996 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:0.93/min:0.01)\n",
      "[3] dimension 50, full-rank, laplace done: 9480.745903968811 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:0.89/min:0.00)\n",
      "[3] dimension 50, half-rank, laplace done: 9570.737503767014 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:1.31/min:0.01)\n",
      "[3] dimension 50, low-rank, laplace done: 9729.943980932236 seconds elapsed...\n",
      "distances distribution(avg:0.31/max:0.49/min:0.16)\n",
      "[4] dimension 20, full-rank, gaussian done: 9924.735792398453 seconds elapsed...\n",
      "distances distribution(avg:0.31/max:0.56/min:0.12)\n",
      "[4] dimension 20, half-rank, gaussian done: 10125.036931991577 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:0.86/min:0.02)\n",
      "[4] dimension 20, low-rank, gaussian done: 10270.287193059921 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:2.01/min:0.06)\n",
      "[4] dimension 20, full-rank, t done: 10357.164594650269 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:1.68/min:0.08)\n",
      "[4] dimension 20, half-rank, t done: 10483.148913383484 seconds elapsed...\n",
      "distances distribution(avg:0.24/max:1.75/min:0.00)\n",
      "[4] dimension 20, low-rank, t done: 10648.674579381943 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:0.94/min:0.02)\n",
      "[4] dimension 20, full-rank, laplace done: 10724.092428445816 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:1.16/min:0.01)\n",
      "[4] dimension 20, half-rank, laplace done: 10825.925873041153 seconds elapsed...\n",
      "distances distribution(avg:0.25/max:1.24/min:0.00)\n",
      "[4] dimension 20, low-rank, laplace done: 10994.780377864838 seconds elapsed...\n",
      "distances distribution(avg:0.32/max:0.43/min:0.22)\n",
      "[4] dimension 50, full-rank, gaussian done: 11115.428703546524 seconds elapsed...\n",
      "distances distribution(avg:0.32/max:0.50/min:0.16)\n",
      "[4] dimension 50, half-rank, gaussian done: 11333.967941761017 seconds elapsed...\n",
      "distances distribution(avg:0.30/max:0.64/min:0.08)\n",
      "[4] dimension 50, low-rank, gaussian done: 11537.561816692352 seconds elapsed...\n",
      "distances distribution(avg:0.29/max:2.58/min:0.09)\n",
      "[4] dimension 50, full-rank, t done: 11617.27402639389 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:2.89/min:0.09)\n",
      "[4] dimension 50, half-rank, t done: 11711.860798120499 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:2.30/min:0.04)\n",
      "[4] dimension 50, low-rank, t done: 11917.383340120316 seconds elapsed...\n",
      "distances distribution(avg:0.28/max:0.83/min:0.00)\n",
      "[4] dimension 50, full-rank, laplace done: 12009.949054479599 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:1.07/min:0.01)\n",
      "[4] dimension 50, half-rank, laplace done: 12102.121864080429 seconds elapsed...\n",
      "distances distribution(avg:0.27/max:1.16/min:0.01)\n",
      "[4] dimension 50, low-rank, laplace done: 12275.410030841827 seconds elapsed...\n"
     ]
    }
   ],
   "source": [
    "n_rand = 10\n",
    "n_sampless = [1000] #,300,25,100]\n",
    "sampling_process_iter = 100\n",
    "\n",
    "pop_dist_types = ['gaussian','t','laplace']\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "dims = [2,5,10,20,50,100,500]\n",
    "for i_c in range(n_rand):\n",
    "    for n_samples in n_sampless:\n",
    "        result_compr = {}\n",
    "        for dim in dims:\n",
    "            seed = 50+dim+i_c\n",
    "            np.random.seed(seed)\n",
    "            manifold = Euclidean(dim)\n",
    "            result_compr[dim] = {}\n",
    "            \n",
    "            mu = np.array([0.0]*dim)\n",
    "                    \n",
    "            for pop_dist_type in pop_dist_types:\n",
    "                result_compr[dim][pop_dist_type] = {}\n",
    "                \n",
    "                for u,u_covs in covs[dim].items():\n",
    "                    try:\n",
    "                        res_ = riemannian_sample_variance_comparison_euclidean(\n",
    "                            manifold=manifold,\n",
    "                            mu=mu,\n",
    "                            cov=u_covs[0],\n",
    "                            pop_dist_type=pop_dist_type,\n",
    "                            n_samples=n_samples,\n",
    "                            sample_iter=sampling_process_iter\n",
    "                        )\n",
    "                        result_compr[dim][pop_dist_type][u] = res_\n",
    "                        print(f'[{i_c}] dimension {dim}, {u}, {pop_dist_type} done: {time.time()-tic} seconds elapsed...')\n",
    "                    except ValueError:\n",
    "                        print(f'[{i_c}] [dimension {dim}, {u}, {pop_dist_type}] norm exploding error ...')\n",
    "                        \n",
    "                \n",
    "        with open(f'euclidean/varofsamplemean_simul_n{n_samples}_cov3type_mest_{i_c}.pkl','wb') as f_:\n",
    "            pickle.dump(result_compr,f_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de08ffe1",
   "metadata": {},
   "source": [
    "## different random seed test (d=10, low-rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27080de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rand = 10\n",
    "n_sampless = [1000] #,300,25,100]\n",
    "sampling_process_iter = 100\n",
    "\n",
    "\n",
    "pop_dist_types = ['gaussian','t','laplace']\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "dims = [10] \n",
    "for i_c in range(n_rand):\n",
    "    for n_samples in n_sampless:\n",
    "        result_compr = {}\n",
    "        for dim in dims:\n",
    "            seed = 5300+dim+i_c\n",
    "            np.random.seed(seed)\n",
    "            manifold = Euclidean(dim)\n",
    "            result_compr[dim] = {}\n",
    "            \n",
    "            mu = np.array([1.0]+[0.0]*dim)\n",
    "                    \n",
    "            for pop_dist_type in pop_dist_types:\n",
    "                result_compr[dim][pop_dist_type] = {}\n",
    "                \n",
    "                for u,u_covs in covs[dim].items():\n",
    "                    try:\n",
    "                        res_ = riemannian_sample_variance_comparison_euclidean(\n",
    "                            manifold=manifold,\n",
    "                            mu=mu,\n",
    "                            cov=u_covs[0],\n",
    "                            pop_dist_type=pop_dist_type,\n",
    "                            n_samples=n_samples,\n",
    "                            sample_iter=sampling_process_iter,\n",
    "                        )\n",
    "                        result_compr[dim][pop_dist_type][u] = res_\n",
    "                        print(f'dimension {dim}, {u}, {pop_dist_type} done: {time.time()-tic} seconds elapsed...')\n",
    "                    except ValueError:\n",
    "                        print(f'[dimension {dim}, {u}, {pop_dist_type}] norm exploding error ...')\n",
    "                        \n",
    "\n",
    "        with open(f'old_rawdata/euclidean_3_seedtest/varofsamplemean_simul_n{n_samples}_dim10_cov3type_mest_251105_{i_c}.pkl','wb') as f_:\n",
    "            pickle.dump(result_compr,f_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
